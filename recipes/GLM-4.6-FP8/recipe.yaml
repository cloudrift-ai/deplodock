model:
  huggingface: "zai-org/GLM-4.6-FP8"

engine:
  llm:
    tensor_parallel_size: 8
    pipeline_parallel_size: 1
    gpu_memory_utilization: 0.9
    context_length: 16384
    max_concurrent_requests: 512
    vllm:
      image: "vllm/vllm-openai:latest"
      extra_args: "--kv-cache-dtype fp8"

benchmark:
  max_concurrency: 128
  num_prompts: 256
  random_input_len: 8000
  random_output_len: 8000

variants:
  8xH200:
    gpu: "NVIDIA H200 141GB"
    gpu_count: 8
    benchmark:
      max_concurrency: 256
      num_prompts: 512
  8xB200:
    gpu: "NVIDIA B200"
    gpu_count: 8
    engine:
      llm:
        vllm:
          extra_args: "--kv-cache-dtype fp8 --enable-expert-parallel"
    benchmark:
      max_concurrency: 256
      num_prompts: 512
  8xH100:
    gpu: "NVIDIA H100 80GB"
    gpu_count: 8
    engine:
      llm:
        max_concurrent_requests: 256
        vllm:
          extra_args: "--kv-cache-dtype fp8"
  8xPro6000:
    gpu: "NVIDIA RTX PRO 6000 Server Edition"
    gpu_count: 8
    engine:
      llm:
        max_concurrent_requests: 256
        vllm:
          extra_args: "--kv-cache-dtype fp8"
    benchmark:
      max_concurrency: 64
      num_prompts: 128
